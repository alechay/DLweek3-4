{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alechay/opt/anaconda3/envs/DLweek3-4/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "\n",
    "# dltk compatible with tensorflow 1\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dltk.io.augmentation import *\n",
    "from dltk.io.preprocessing import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer helper class for benchmarking reading methods\n",
    "class Timer(object):\n",
    "    \"\"\"Timer class\n",
    "       Wrap a will with a timing function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.t = time.time()\n",
    "        \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"{} took {} seconds\".format(\n",
    "        self.name, time.time() - self.t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "batch_size = 5\n",
    "iterations = 100\n",
    "\n",
    "# Define the desired shapes and types of the training examples to pass to `read_fn`:\n",
    "reader_params = {'n_examples': 1,\n",
    "                 'example_size': [128, 224, 224],\n",
    "                 'extract_examples': True}\n",
    "\n",
    "reader_example_shapes = {'features': {'x': reader_params['example_size'] + [1,]},\n",
    "                         'labels': {'y': []}}\n",
    " \n",
    "reader_example_dtypes = {'features': {'x': tf.float32},\n",
    "                         'labels': {'y': tf.int32}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using feed dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read some demo data from csv\n",
    "all_filenames = pd.read_csv(\n",
    "    '../DLTK/demographic_HH.csv',\n",
    "    dtype=object,\n",
    "    keep_default_na=False,\n",
    "    na_values=[]).to_numpy()\n",
    "\n",
    "# For demo purposes, we will only use the first 10 datasets from IXI HH\n",
    "all_filenames = all_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_references, mode, params=None):\n",
    "    \n",
    "    data = {'features': [], 'labels': []}\n",
    "    \n",
    "    # We define a `read_fn` and iterate through the `file_references`, which\n",
    "    # can contain information about the data to be read (e.g. a file path):\n",
    "    for meta_data in file_references:\n",
    "        \n",
    "        # Here, we parse the `subject_id` to construct a file path to read\n",
    "        # an image from.\n",
    "        subject_id = meta_data[0]\n",
    "        data_path = '../DLTK/1mm'\n",
    "        t1_fn = os.path.join(data_path, '{}/T1_1mm.nii.gz'.format(subject_id))\n",
    "        \n",
    "        # Read the .nii image containing a brain volume with SimpleITK and get \n",
    "        # the numpy array:\n",
    "        sitk_t1 = sitk.ReadImage(t1_fn)\n",
    "        t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "\n",
    "        # Normalise the image to zero mean/unit std dev:\n",
    "        t1 = whitening(t1)\n",
    "        \n",
    "        # Create a 4D Tensor with a dummy dimension for channels\n",
    "        t1 = t1[..., np.newaxis]\n",
    "\n",
    "        # Labels: Here, we parse the class *sex* from the file_references \n",
    "        # \\in [1,2] and shift them to \\in [0,1] for training:\n",
    "        sex = np.int32(meta_data[1]) - 1\n",
    "        y = sex\n",
    "        \n",
    "        # If training should be done on image patches for improved mixing, \n",
    "        # memory limitations or class balancing, call a patch extractor\n",
    "        if params['extract_examples']:\n",
    "            images = extract_random_example_array(\n",
    "                t1,\n",
    "                example_size=params['example_size'],\n",
    "                n_examples=params['n_examples'])\n",
    "            \n",
    "            # Loop the extracted image patches\n",
    "            for e in range(params['n_examples']):\n",
    "                data['features'].append(images[e].astype(np.float32))\n",
    "                data['labels'].append(y.astype(np.int32))\n",
    "                     \n",
    "        # If desired (i.e. for evaluation, etc.), return the full images\n",
    "        else:\n",
    "            data['features'].append(images)\n",
    "            data['labels'].append(y.astype(np.int32))\n",
    "\n",
    "    data['features'] = np.array(data['features'])\n",
    "    data['labels'] = np.vstack(data['labels'])\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data into memory\n",
    "data = load_data(all_filenames, \n",
    "                 tf.estimator.ModeKeys.TRAIN, reader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(reader_example_dtypes['features']['x'], \n",
    "                   [None, 128, 224, 224, 1])\n",
    "y = tf.placeholder(reader_example_dtypes['labels']['y'], \n",
    "                   [None, 1])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.repeat(None)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "# Check that features and labels dimensions match\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "nx = iterator.get_next()\n",
    "\n",
    "with tf.train.MonitoredTrainingSession() as sess_dict:\n",
    "    # Initialize iterator\n",
    "    sess_dict.run(iterator.initializer, \n",
    "               feed_dict={x: features, y: labels})\n",
    "    \n",
    "    with Timer('Feed dictionary'):\n",
    "        # Timed feed dictionary example\n",
    "        for i in range(iterations):\n",
    "            # Get next features-labels pair\n",
    "            dict_batch_feat, dict_batch_lbl = sess_dict.run(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the `dict_batch_feat` using matplotlib.\n",
    "input_tensor_shape = dict_batch_feat.shape\n",
    "center_slices = [s//2 for s in input_tensor_shape]\n",
    "\n",
    "# Visualise the `gen_batch_feat` using matplotlib.\n",
    "f, axarr = plt.subplots(1, input_tensor_shape[0], figsize=(15,5));\n",
    "f.suptitle('Visualisation of the `dict_batch_feat` input tensor with shape={}'.format(input_tensor_shape))\n",
    "\n",
    "for batch_id in range(input_tensor_shape[0]):\n",
    "    # Extract a center slice image\n",
    "    img_slice_ = np.squeeze(dict_batch_feat[batch_id, center_slices[1], :, :, :])\n",
    "    img_slice_ = np.flip(img_slice_, axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    axarr[batch_id].imshow(img_slice_, cmap='gray');\n",
    "    axarr[batch_id].axis('off')\n",
    "    axarr[batch_id].set_title('batch_id={}'.format(batch_id))\n",
    "    \n",
    "f.subplots_adjust(wspace=0.05, hspace=0, top=0.8)\n",
    "plt.show(); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLweek3-4)",
   "language": "python",
   "name": "dlweek3-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
